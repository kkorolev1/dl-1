{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e9c822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2023-01-16 22:06:05--  https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.90.22, 52.216.25.134, 52.217.104.22, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.90.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4475746 (4.3M) [application/zip]\n",
      "Saving to: ‘wikitext-2-v1.zip’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1%  386K 11s\n",
      "    50K .......... .......... .......... .......... ..........  2%  390K 11s\n",
      "   100K .......... .......... .......... .......... ..........  3%  396K 11s\n",
      "   150K .......... .......... .......... .......... ..........  4%  189K 14s\n",
      "   200K .......... .......... .......... .......... ..........  5%  107M 11s\n",
      "   250K .......... .......... .......... .......... ..........  6%  115M 9s\n",
      "   300K .......... .......... .......... .......... ..........  8%  117M 7s\n",
      "   350K .......... .......... .......... .......... ..........  9%  117M 6s\n",
      "   400K .......... .......... .......... .......... .......... 10%  114M 6s\n",
      "   450K .......... .......... .......... .......... .......... 11%  120M 5s\n",
      "   500K .......... .......... .......... .......... .......... 12%  429K 5s\n",
      "   550K .......... .......... .......... .......... .......... 13% 10.4M 5s\n",
      "   600K .......... .......... .......... .......... .......... 14% 10.5M 4s\n",
      "   650K .......... .......... .......... .......... .......... 16%  423K 5s\n",
      "   700K .......... .......... .......... .......... .......... 17% 10.5M 4s\n",
      "   750K .......... .......... .......... .......... .......... 18% 11.1M 4s\n",
      "   800K .......... .......... .......... .......... .......... 19%  425K 4s\n",
      "   850K .......... .......... .......... .......... .......... 20% 13.9M 4s\n",
      "   900K .......... .......... .......... .......... .......... 21% 11.1M 4s\n",
      "   950K .......... .......... .......... .......... .......... 22%  428K 4s\n",
      "  1000K .......... .......... .......... .......... .......... 24% 8.41M 4s\n",
      "  1050K .......... .......... .......... .......... .......... 25% 11.8M 3s\n",
      "  1100K .......... .......... .......... .......... .......... 26%  432K 4s\n",
      "  1150K .......... .......... .......... .......... .......... 27% 8.27M 3s\n",
      "  1200K .......... .......... .......... .......... .......... 28% 10.5M 3s\n",
      "  1250K .......... .......... .......... .......... .......... 29% 11.1M 3s\n",
      "  1300K .......... .......... .......... .......... .......... 30%  430K 3s\n",
      "  1350K .......... .......... .......... .......... .......... 32% 9.56M 3s\n",
      "  1400K .......... .......... .......... .......... .......... 33% 11.1M 3s\n",
      "  1450K .......... .......... .......... .......... .......... 34%  432K 3s\n",
      "  1500K .......... .......... .......... .......... .......... 35% 9.93M 3s\n",
      "  1550K .......... .......... .......... .......... .......... 36% 10.5M 3s\n",
      "  1600K .......... .......... .......... .......... .......... 37%  435K 3s\n",
      "  1650K .......... .......... .......... .......... .......... 38% 8.84M 3s\n",
      "  1700K .......... .......... .......... .......... .......... 40% 14.9M 2s\n",
      "  1750K .......... .......... .......... .......... .......... 41% 10.6M 2s\n",
      "  1800K .......... .......... .......... .......... .......... 42%  436K 2s\n",
      "  1850K .......... .......... .......... .......... .......... 43% 9.29M 2s\n",
      "  1900K .......... .......... .......... .......... .......... 44% 9.80M 2s\n",
      "  1950K .......... .......... .......... .......... .......... 45% 11.1M 2s\n",
      "  2000K .......... .......... .......... .......... .......... 46%  434K 2s\n",
      "  2050K .......... .......... .......... .......... .......... 48% 10.0M 2s\n",
      "  2100K .......... .......... .......... .......... .......... 49% 10.5M 2s\n",
      "  2150K .......... .......... .......... .......... .......... 50%  440K 2s\n",
      "  2200K .......... .......... .......... .......... .......... 51% 8.34M 2s\n",
      "  2250K .......... .......... .......... .......... .......... 52% 11.1M 2s\n",
      "  2300K .......... .......... .......... .......... .......... 53% 10.4M 2s\n",
      "  2350K .......... .......... .......... .......... .......... 54%  437K 2s\n",
      "  2400K .......... .......... .......... .......... .......... 56% 9.02M 2s\n",
      "  2450K .......... .......... .......... .......... .......... 57% 11.7M 2s\n",
      "  2500K .......... .......... .......... .......... .......... 58% 10.5M 2s\n",
      "  2550K .......... .......... .......... .......... .......... 59%  444K 2s\n",
      "  2600K .......... .......... .......... .......... .......... 60% 9.20M 1s\n",
      "  2650K .......... .......... .......... .......... .......... 61% 10.6M 1s\n",
      "  2700K .......... .......... .......... .......... .......... 62% 11.0M 1s\n",
      "  2750K .......... .......... .......... .......... .......... 64%  439K 1s\n",
      "  2800K .......... .......... .......... .......... .......... 65% 8.93M 1s\n",
      "  2850K .......... .......... .......... .......... .......... 66% 11.1M 1s\n",
      "  2900K .......... .......... .......... .......... .......... 67% 10.4M 1s\n",
      "  2950K .......... .......... .......... .......... .......... 68%  440K 1s\n",
      "  3000K .......... .......... .......... .......... .......... 69% 9.56M 1s\n",
      "  3050K .......... .......... .......... .......... .......... 70% 10.5M 1s\n",
      "  3100K .......... .......... .......... .......... .......... 72% 11.1M 1s\n",
      "  3150K .......... .......... .......... .......... .......... 73%  438K 1s\n",
      "  3200K .......... .......... .......... .......... .......... 74% 11.0M 1s\n",
      "  3250K .......... .......... .......... .......... .......... 75% 10.5M 1s\n",
      "  3300K .......... .......... .......... .......... .......... 76% 1.06M 1s\n",
      "  3350K .......... .......... .......... .......... .......... 77%  690K 1s\n",
      "  3400K .......... .......... .......... .......... .......... 78% 16.1M 1s\n",
      "  3450K .......... .......... .......... .......... .......... 80% 10.6M 1s\n",
      "  3500K .......... .......... .......... .......... .......... 81% 11.0M 1s\n",
      "  3550K .......... .......... .......... .......... .......... 82%  438K 1s\n",
      "  3600K .......... .......... .......... .......... .......... 83% 10.6M 1s\n",
      "  3650K .......... .......... .......... .......... .......... 84% 10.5M 1s\n",
      "  3700K .......... .......... .......... .......... .......... 85% 11.1M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 86%  440K 0s\n",
      "  3800K .......... .......... .......... .......... .......... 88% 10.7M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 89% 10.6M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 90% 1.08M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 91%  686K 0s\n",
      "  4000K .......... .......... .......... .......... .......... 92% 11.1M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 93% 11.1M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 94% 1.07M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 96%  685K 0s\n",
      "  4200K .......... .......... .......... .......... .......... 97% 11.0M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 98% 16.1M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 99% 11.2M 0s\n",
      "  4350K .......... ..........                                 100%  491K=3.4s\n",
      "\n",
      "2023-01-16 22:06:09 (1.27 MB/s) - ‘wikitext-2-v1.zip’ saved [4475746/4475746]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  wikitext-2-v1.zip\n",
      "   creating: wikitext-2/\n",
      "  inflating: wikitext-2/wiki.test.tokens  \n",
      "  inflating: wikitext-2/wiki.valid.tokens  \n",
      "  inflating: wikitext-2/wiki.train.tokens  \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "wget https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip\n",
    "unzip wikitext-2-v1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "crude-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fallen-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TOKENS = 'wikitext-2/wiki.train.tokens'\n",
    "VALID_TOKENS = 'wikitext-2/wiki.valid.tokens'\n",
    "\n",
    "SKIPGRAM_N_WORDS = 4\n",
    "MIN_WORD_FREQUENCY = 20\n",
    "MAX_SEQUENCE_LENGTH = 256\n",
    "\n",
    "EMBED_DIM = 256\n",
    "EMBED_MAX_NORM = 1\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a9ea756",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english', language='en')\n",
    "\n",
    "def load_and_preprocess_dataset(path):\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    data = list(filter(\n",
    "        lambda sent: len(sent) > SKIPGRAM_N_WORDS * 2,\n",
    "        map(tokenizer, lines)\n",
    "    ))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc00edb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num sentences: train - 17715, valid - 1892)\n",
      "Total tokens: train - 2014338, valid - 211057)\n",
      "Average tokens in sentence: 113.71\n"
     ]
    }
   ],
   "source": [
    "train_data = load_and_preprocess_dataset(TRAIN_TOKENS)\n",
    "valid_data = load_and_preprocess_dataset(VALID_TOKENS)\n",
    "\n",
    "total_train_tokens = sum(len(sent) for sent in train_data)\n",
    "total_valid_tokens = sum(len(sent) for sent in valid_data)\n",
    "\n",
    "print(f'Num sentences: train - {len(train_data)}, valid - {len(valid_data)})')\n",
    "print(f'Total tokens: train - {total_train_tokens}, valid - {total_valid_tokens})')\n",
    "print(f'Average tokens in sentence: {total_train_tokens / len(train_data):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc2d5391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = sns.displot([len(sent) for sent in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb683b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 8076\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab_from_iterator(train_data, specials=[\"<unk>\"], min_freq=MIN_WORD_FREQUENCY)\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "print(f'Vocab size: {VOCAB_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aecca99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['during',\n",
       " 'the',\n",
       " 'month',\n",
       " 'of',\n",
       " 'august',\n",
       " ',',\n",
       " '1862',\n",
       " ',',\n",
       " 'the',\n",
       " 'following',\n",
       " 'work',\n",
       " 'was',\n",
       " 'performed',\n",
       " '<unk>',\n",
       " 'one',\n",
       " 'pair',\n",
       " 'of',\n",
       " 'musket',\n",
       " 'bullet',\n",
       " 'moulds',\n",
       " '10',\n",
       " '@',\n",
       " ',',\n",
       " '@',\n",
       " '000',\n",
       " 'buck',\n",
       " '&',\n",
       " 'ball',\n",
       " 'shot',\n",
       " 'cartridges',\n",
       " 'repaired',\n",
       " '750',\n",
       " '<unk>',\n",
       " ',',\n",
       " 'shotguns',\n",
       " ',',\n",
       " 'and',\n",
       " 'rifles',\n",
       " 'received',\n",
       " 'and',\n",
       " 'repaired',\n",
       " 'ordnance',\n",
       " 'stores',\n",
       " 'and',\n",
       " '<unk>',\n",
       " 'performed',\n",
       " 'guard',\n",
       " ',',\n",
       " 'office',\n",
       " ',',\n",
       " 'and',\n",
       " 'police',\n",
       " 'duties',\n",
       " 'inspected',\n",
       " '<unk>',\n",
       " 'at',\n",
       " 'camden',\n",
       " 'and',\n",
       " 'arkadelphia',\n",
       " '.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7a96566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56,\n",
       " 1,\n",
       " 689,\n",
       " 4,\n",
       " 181,\n",
       " 2,\n",
       " 5892,\n",
       " 2,\n",
       " 1,\n",
       " 133,\n",
       " 138,\n",
       " 9,\n",
       " 469,\n",
       " 0,\n",
       " 40,\n",
       " 1457,\n",
       " 4,\n",
       " 0,\n",
       " 6904,\n",
       " 0,\n",
       " 160,\n",
       " 19,\n",
       " 2,\n",
       " 19,\n",
       " 98,\n",
       " 0,\n",
       " 379,\n",
       " 749,\n",
       " 788,\n",
       " 0,\n",
       " 6648,\n",
       " 7096,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 2668,\n",
       " 200,\n",
       " 5,\n",
       " 6648,\n",
       " 6450,\n",
       " 3980,\n",
       " 5,\n",
       " 0,\n",
       " 469,\n",
       " 2055,\n",
       " 2,\n",
       " 697,\n",
       " 2,\n",
       " 5,\n",
       " 714,\n",
       " 2964,\n",
       " 0,\n",
       " 0,\n",
       " 25,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(train_data[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced8f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate_fn for Skip-Gram model to be used with Dataloader.\n",
    "    `batch` is expected to be list of text paragrahs.\n",
    "\n",
    "    Context is represented as N=SKIPGRAM_N_WORDS past words \n",
    "    and N=SKIPGRAM_N_WORDS future words.\n",
    "\n",
    "    Long paragraphs will be truncated to contain\n",
    "    no more that MAX_SEQUENCE_LENGTH tokens.\n",
    "\n",
    "    Each element in `batch_input` is a middle word.\n",
    "    Each element in `batch_output` is a context word.\n",
    "    \"\"\"\n",
    "    batch_input, batch_output = [], []\n",
    "    for text in batch:\n",
    "        text_tokens_ids = vocab(text)\n",
    "\n",
    "        if MAX_SEQUENCE_LENGTH:\n",
    "            text_tokens_ids = text_tokens_ids[:MAX_SEQUENCE_LENGTH]\n",
    "\n",
    "        for idx in range(len(text_tokens_ids) - SKIPGRAM_N_WORDS * 2):\n",
    "            token_id_sequence = text_tokens_ids[idx : (idx + SKIPGRAM_N_WORDS * 2 + 1)]\n",
    "            input_ = token_id_sequence.pop(SKIPGRAM_N_WORDS)\n",
    "            outputs = token_id_sequence\n",
    "\n",
    "            batch_input += [input_] * len(outputs)\n",
    "            batch_output += outputs\n",
    "\n",
    "    batch_input = torch.tensor(batch_input, dtype=torch.long)\n",
    "    batch_output = torch.tensor(batch_output, dtype=torch.long)\n",
    "    return batch_input, batch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb24c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, num_workers=4,\n",
    "                          pin_memory=True, collate_fn=collate_fn, shuffle=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, num_workers=4,\n",
    "                          pin_memory=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cab78c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8e3ac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def plot_losses(train_losses, valid_losses):\n",
    "    clear_output()\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='train', color='deepskyblue', linewidth=2)\n",
    "    plt.plot(range(1, len(valid_losses) + 1), valid_losses, label='valid', color='springgreen', linewidth=2)\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b952232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_epoch(model, optimizer, criterion, train_loader, tqdm_desc):\n",
    "    train_loss, num_batches = 0.0, 1\n",
    "    model.train()\n",
    "    for inputs, outputs in tqdm(train_loader, desc=tqdm_desc):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, outputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_epoch(model, criterion, valid_loader, tqdm_desc):\n",
    "    valid_loss, num_batches = 0.0, 0\n",
    "    model.eval()\n",
    "    for inputs, outputs in tqdm(valid_loader, desc=tqdm_desc):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "\n",
    "        logits = model(inputs)\n",
    "        loss = criterion(logits, outputs)\n",
    "\n",
    "        valid_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    valid_loss /= num_batches\n",
    "    return valid_loss\n",
    "\n",
    "\n",
    "def train(model, optimizer, scheduler, criterion, train_loader, valid_loader, num_epochs):\n",
    "    train_losses, valid_losses = [], []\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss = training_epoch(\n",
    "            model, optimizer, criterion, train_loader,\n",
    "            tqdm_desc=f'Training {epoch}/{num_epochs}'\n",
    "        )\n",
    "        valid_loss = validation_epoch(\n",
    "            model, criterion, valid_loader,\n",
    "            tqdm_desc=f'Validating {epoch}/{num_epochs}'\n",
    "        )\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        train_losses += [train_loss]\n",
    "        valid_losses += [valid_loss]\n",
    "        plot_losses(train_losses, valid_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e87f5a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2VecModel(nn.Module):\n",
    "    def __init__(self, embed_dim, embed_max_norm, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim,\n",
    "                                   max_norm=embed_max_norm)\n",
    "        self.decoder = nn.Linear(embed_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, tokens):\n",
    "        embeds = self.embeds(tokens)\n",
    "        logits = self.decoder(embeds)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "094a0bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2VecModel(embed_dim=EMBED_DIM, embed_max_norm=EMBED_MAX_NORM,\n",
    "                      vocab_size=VOCAB_SIZE).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, NUM_EPOCHS)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9adf27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa224f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a82c207dd2f41ecac493d6655b5a505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training 1/20:   0%|          | 0/1108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 460.00 MiB (GPU 0; 11.77 GiB total capacity; 2.01 GiB already allocated; 406.19 MiB free; 3.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(model, optimizer, scheduler, criterion, train_loader, valid_loader, NUM_EPOCHS)\n",
      "Cell \u001b[0;32mIn[14], line 43\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, criterion, train_loader, valid_loader, num_epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m train_losses, valid_losses \u001b[39m=\u001b[39m [], []\n\u001b[1;32m     42\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> 43\u001b[0m     train_loss \u001b[39m=\u001b[39m training_epoch(\n\u001b[1;32m     44\u001b[0m         model, optimizer, criterion, train_loader,\n\u001b[1;32m     45\u001b[0m         tqdm_desc\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mTraining \u001b[39;49m\u001b[39m{\u001b[39;49;00mepoch\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mnum_epochs\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     46\u001b[0m     )\n\u001b[1;32m     47\u001b[0m     valid_loss \u001b[39m=\u001b[39m validation_epoch(\n\u001b[1;32m     48\u001b[0m         model, criterion, valid_loader,\n\u001b[1;32m     49\u001b[0m         tqdm_desc\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidating \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     50\u001b[0m     )\n\u001b[1;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m scheduler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m, in \u001b[0;36mtraining_epoch\u001b[0;34m(model, optimizer, criterion, train_loader, tqdm_desc)\u001b[0m\n\u001b[1;32m      9\u001b[0m logits \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     10\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, outputs)\n\u001b[0;32m---> 11\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     12\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     14\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.conda/envs/kkorolev/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/kkorolev/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 460.00 MiB (GPU 0; 11.77 GiB total capacity; 2.01 GiB already allocated; 406.19 MiB free; 3.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, scheduler, criterion, train_loader, valid_loader, NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ecd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kkorolev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "f404e0e273a4f0796c7e39d3cee33e66306a58991d52ed6c42396fee84b35bae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
